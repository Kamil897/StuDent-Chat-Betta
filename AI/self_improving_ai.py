"""
–°–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–∞—è—Å—è —Å–∏—Å—Ç–µ–º–∞ –ò–ò
–†–µ–∞–ª–∏–∑—É–µ—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –º–µ—Ç–∞–æ–±—É—á–µ–Ω–∏—è, —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏ –∏ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è
"""

import json
import os
import pickle
import random
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import numpy as np


@dataclass
class PerformanceMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã"""
    accuracy: float = 0.0
    response_time: float = 0.0
    knowledge_base_size: int = 0
    improvement_rate: float = 0.0
    total_interactions: int = 0
    successful_tasks: int = 0
    timestamp: str = ""


@dataclass
class AIParameters:
    """–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ò–ò, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã"""
    learning_rate: float = 0.01
    exploration_rate: float = 0.1
    memory_capacity: int = 1000
    decision_threshold: float = 0.5
    creativity_factor: float = 0.3
    confidence_threshold: float = 0.7


class KnowledgeBase:
    """–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è —Ä–∞—Å—Ç–µ—Ç –∏ —É–ª—É—á—à–∞–µ—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º"""
    
    def __init__(self, storage_path: str = "knowledge_base.json"):
        self.storage_path = storage_path
        self.knowledge: Dict[str, Any] = {}
        self.patterns: Dict[str, List[str]] = {}
        self.solutions: Dict[str, Any] = {}
        self.load()
    
    def load(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ —Ñ–∞–π–ª–∞"""
        if os.path.exists(self.storage_path):
            try:
                with open(self.storage_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.knowledge = data.get('knowledge', {})
                    self.patterns = data.get('patterns', {})
                    self.solutions = data.get('solutions', {})
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
    
    def save(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –≤ —Ñ–∞–π–ª"""
        try:
            data = {
                'knowledge': self.knowledge,
                'patterns': self.patterns,
                'solutions': self.solutions,
                'last_updated': datetime.now().isoformat()
            }
            with open(self.storage_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
    
    def add_knowledge(self, key: str, value: Any, category: str = "general"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∑–Ω–∞–Ω–∏—è"""
        if category not in self.knowledge:
            self.knowledge[category] = {}
        self.knowledge[category][key] = {
            'value': value,
            'timestamp': datetime.now().isoformat(),
            'usage_count': 0
        }
        self.save()
    
    def get_knowledge(self, key: str, category: str = "general") -> Optional[Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏—è –∏–∑ –±–∞–∑—ã"""
        if category in self.knowledge and key in self.knowledge[category]:
            self.knowledge[category][key]['usage_count'] += 1
            return self.knowledge[category][key]['value']
        return None
    
    def learn_pattern(self, pattern_type: str, pattern: str):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö"""
        if pattern_type not in self.patterns:
            self.patterns[pattern_type] = []
        if pattern not in self.patterns[pattern_type]:
            self.patterns[pattern_type].append(pattern)
            self.save()
    
    def find_similar_patterns(self, query: str) -> List[str]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        results = []
        for pattern_type, patterns in self.patterns.items():
            for pattern in patterns:
                if query.lower() in pattern.lower() or pattern.lower() in query.lower():
                    results.append(pattern)
        return results
    
    def get_size(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        total = sum(len(cat) for cat in self.knowledge.values())
        total += sum(len(patterns) for patterns in self.patterns.values())
        total += len(self.solutions)
        return total


class SelfEvaluator:
    """–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ—Ü–µ–Ω–∫–∏ –∏ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
    
    def __init__(self):
        self.evaluation_history: List[Dict[str, Any]] = []
        self.feedback_loop: List[Dict[str, Any]] = []
    
    def evaluate_response(self, query: str, response: str, 
                         execution_time: float) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞"""
        metrics = {
            'relevance': self._calculate_relevance(query, response),
            'completeness': self._calculate_completeness(response),
            'efficiency': max(0, 1.0 - execution_time / 10.0),  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏
            'confidence': self._calculate_confidence(response)
        }
        
        overall_score = sum(metrics.values()) / len(metrics)
        metrics['overall'] = overall_score
        
        evaluation = {
            'query': query,
            'response': response,
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        self.evaluation_history.append(evaluation)
        return metrics
    
    def _calculate_relevance(self, query: str, response: str) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞"""
        query_words = set(query.lower().split())
        response_words = set(response.lower().split())
        if len(query_words) == 0:
            return 0.0
        intersection = query_words.intersection(response_words)
        return len(intersection) / len(query_words)
    
    def _calculate_completeness(self, response: str) -> float:
        """–†–∞—Å—á–µ—Ç –ø–æ–ª–Ω–æ—Ç—ã –æ—Ç–≤–µ—Ç–∞"""
        # –ë–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–µ (—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º)
        length_score = min(1.0, len(response.split()) / 50.0)
        # –ù–∞–ª–∏—á–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        structure_score = 1.0 if any(char in response for char in [':', '-', '\n']) else 0.5
        return (length_score + structure_score) / 2.0
    
    def _calculate_confidence(self, response: str) -> float:
        """–†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–µ"""
        # –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö
        has_numbers = any(char.isdigit() for char in response)
        has_structure = len(response.split()) > 10
        confidence = 0.5
        if has_numbers:
            confidence += 0.2
        if has_structure:
            confidence += 0.3
        return min(1.0, confidence)
    
    def get_improvement_suggestions(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        if len(self.evaluation_history) < 3:
            return ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"]
        
        recent_evaluations = self.evaluation_history[-10:]
        avg_relevance = np.mean([e['metrics']['relevance'] for e in recent_evaluations])
        avg_completeness = np.mean([e['metrics']['completeness'] for e in recent_evaluations])
        avg_efficiency = np.mean([e['metrics']['efficiency'] for e in recent_evaluations])
        
        suggestions = []
        if avg_relevance < 0.6:
            suggestions.append("–£–ª—É—á—à–∏—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤ - –ª—É—á—à–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã")
        if avg_completeness < 0.6:
            suggestions.append("–£–≤–µ–ª–∏—á–∏—Ç—å –ø–æ–ª–Ω–æ—Ç—É –æ—Ç–≤–µ—Ç–æ–≤ - –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π")
        if avg_efficiency < 0.7:
            suggestions.append("–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤")
        
        return suggestions if suggestions else ["–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –Ω–æ—Ä–º–µ"]


class EvolutionaryOptimizer:
    """–≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ò–ò"""
    
    def __init__(self, population_size: int = 10):
        self.population_size = population_size
        self.generation = 0
        self.population: List[Dict[str, AIParameters]] = []
        self.fitness_history: List[float] = []
    
    def initialize_population(self, base_params: AIParameters):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ø—É–ª—è—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        self.population = []
        for _ in range(self.population_size):
            mutated = self._mutate_params(base_params)
            self.population.append({
                'params': mutated,
                'fitness': 0.0
            })
        self.generation = 0
    
    def _mutate_params(self, params: AIParameters) -> AIParameters:
        """–ú—É—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        mutation_rate = 0.1
        new_params = AIParameters(
            learning_rate=max(0.001, params.learning_rate + random.uniform(-mutation_rate, mutation_rate)),
            exploration_rate=max(0.0, min(1.0, params.exploration_rate + random.uniform(-mutation_rate, mutation_rate))),
            memory_capacity=max(100, params.memory_capacity + random.randint(-100, 100)),
            decision_threshold=max(0.0, min(1.0, params.decision_threshold + random.uniform(-0.1, 0.1))),
            creativity_factor=max(0.0, min(1.0, params.creativity_factor + random.uniform(-0.1, 0.1))),
            confidence_threshold=max(0.0, min(1.0, params.confidence_threshold + random.uniform(-0.1, 0.1)))
        )
        return new_params
    
    def evaluate_fitness(self, params: AIParameters, performance: PerformanceMetrics) -> float:
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        fitness = (
            performance.accuracy * 0.4 +
            (1.0 - min(1.0, performance.response_time / 5.0)) * 0.2 +
            min(1.0, performance.knowledge_base_size / 1000.0) * 0.2 +
            performance.improvement_rate * 0.2
        )
        return fitness
    
    def evolve(self, current_performance: PerformanceMetrics) -> AIParameters:
        """–≠–≤–æ–ª—é—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        if not self.population:
            return AIParameters()
        
        # –û—Ü–µ–Ω–∫–∞ —Ç–µ–∫—É—â–µ–π –ø–æ–ø—É–ª—è—Ü–∏–∏
        for individual in self.population:
            individual['fitness'] = self.evaluate_fitness(
                individual['params'], 
                current_performance
            )
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏
        self.population.sort(key=lambda x: x['fitness'], reverse=True)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏
        best_fitness = self.population[0]['fitness']
        self.fitness_history.append(best_fitness)
        
        # –°–µ–ª–µ–∫—Ü–∏—è –∏ —Ä–∞–∑–º–Ω–æ–∂–µ–Ω–∏–µ –ª—É—á—à–∏—Ö
        elite_size = max(1, self.population_size // 4)
        elite = [ind['params'] for ind in self.population[:elite_size]]
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è
        new_population = []
        for i in range(self.population_size):
            if i < elite_size:
                # –≠–ª–∏—Ç–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è
                new_population.append({'params': elite[i], 'fitness': 0.0})
            else:
                # –°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –∏ –º—É—Ç–∞—Ü–∏—è
                parent1 = random.choice(elite)
                parent2 = random.choice(elite)
                child = self._crossover(parent1, parent2)
                child = self._mutate_params(child)
                new_population.append({'params': child, 'fitness': 0.0})
        
        self.population = new_population
        self.generation += 1
        
        return self.population[0]['params']  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    
    def _crossover(self, parent1: AIParameters, parent2: AIParameters) -> AIParameters:
        """–°–∫—Ä–µ—â–∏–≤–∞–Ω–∏–µ –¥–≤—É—Ö –Ω–∞–±–æ—Ä–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        return AIParameters(
            learning_rate=(parent1.learning_rate + parent2.learning_rate) / 2,
            exploration_rate=(parent1.exploration_rate + parent2.exploration_rate) / 2,
            memory_capacity=(parent1.memory_capacity + parent2.memory_capacity) // 2,
            decision_threshold=(parent1.decision_threshold + parent2.decision_threshold) / 2,
            creativity_factor=(parent1.creativity_factor + parent2.creativity_factor) / 2,
            confidence_threshold=(parent1.confidence_threshold + parent2.confidence_threshold) / 2
        )


class SelfImprovingAI:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–µ–≥–æ—Å—è –ò–ò"""
    
    def __init__(self, name: str = "SelfImprovingAI"):
        self.name = name
        self.parameters = AIParameters()
        self.knowledge_base = KnowledgeBase()
        self.evaluator = SelfEvaluator()
        self.optimizer = EvolutionaryOptimizer()
        self.performance = PerformanceMetrics()
        self.optimizer.initialize_population(self.parameters)
        self.history: List[Dict[str, Any]] = []
        
        print(f"ü§ñ {self.name} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"üìä –ù–∞—á–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {asdict(self.parameters)}")
    
    def process(self, query: str) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º"""
        start_time = time.time()
        
        # –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        response = self._generate_response(query)
        
        execution_time = time.time() - start_time
        
        # –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞
        metrics = self.evaluator.evaluate_response(query, response, execution_time)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        self._learn_from_interaction(query, response, metrics)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self._update_performance(metrics, execution_time)
        
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if self.performance.total_interactions % 10 == 0:
            self._self_improve()
        
        return response
    
    def _generate_response(self, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å"""
        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        similar_patterns = self.knowledge_base.find_similar_patterns(query)
        
        # –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        knowledge = self.knowledge_base.get_knowledge(query.lower(), "responses")
        
        if knowledge:
            return knowledge
        elif similar_patterns:
            # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            base_response = similar_patterns[0]
            return f"–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ–ø—ã—Ç–∞: {base_response}. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à –∑–∞–ø—Ä–æ—Å: {query}"
        else:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            return self._create_new_response(query)
    
    def _create_new_response(self, query: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ LLM)
        response_parts = [
            f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å: {query}",
            f"–ò—Å–ø–æ–ª—å–∑—É—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: learning_rate={self.parameters.learning_rate:.3f}",
            "–ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞–Ω–∏–π –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∏—Å—Ç–µ–º—ã."
        ]
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        if random.random() < self.parameters.creativity_factor:
            response_parts.append("–ü—Ä–∏–º–µ–Ω—è—é –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é.")
        
        return " | ".join(response_parts)
    
    def _learn_from_interaction(self, query: str, response: str, metrics: Dict[str, float]):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        if metrics['overall'] > self.parameters.confidence_threshold:
            self.knowledge_base.add_knowledge(
                query.lower(), 
                response, 
                "responses"
            )
            self.knowledge_base.learn_pattern("successful_queries", query)
            self.performance.successful_tasks += 1
    
    def _update_performance(self, metrics: Dict[str, float], execution_time: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        self.performance.total_interactions += 1
        self.performance.accuracy = (
            self.performance.accuracy * 0.9 + metrics['overall'] * 0.1
        )
        self.performance.response_time = (
            self.performance.response_time * 0.9 + execution_time * 0.1
        )
        self.performance.knowledge_base_size = self.knowledge_base.get_size()
        self.performance.timestamp = datetime.now().isoformat()
    
    def _self_improve(self):
        """–ü—Ä–æ—Ü–µ—Å—Å —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è"""
        print("\nüîÑ –ù–∞—á–∏–Ω–∞—é –ø—Ä–æ—Ü–µ—Å—Å —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è...")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        suggestions = self.evaluator.get_improvement_suggestions()
        print(f"üí° –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {suggestions}")
        
        # –≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        old_params = self.parameters
        new_params = self.optimizer.evolve(self.performance)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if self.optimizer.fitness_history:
            if len(self.optimizer.fitness_history) > 1:
                improvement = self.optimizer.fitness_history[-1] - self.optimizer.fitness_history[-2]
                self.performance.improvement_rate = improvement
        
        self.parameters = new_params
        
        print(f"üìà –ü–æ–∫–æ–ª–µ–Ω–∏–µ {self.optimizer.generation}")
        print(f"üìä –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {asdict(self.parameters)}")
        print(f"‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\n")
    
    def get_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        return {
            'name': self.name,
            'parameters': asdict(self.parameters),
            'performance': asdict(self.performance),
            'knowledge_base_size': self.knowledge_base.get_size(),
            'generation': self.optimizer.generation,
            'total_evaluations': len(self.evaluator.evaluation_history)
        }
    
    def save_state(self, filepath: str = "ai_state.pkl"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        state = {
            'parameters': self.parameters,
            'performance': self.performance,
            'generation': self.optimizer.generation,
            'fitness_history': self.optimizer.fitness_history
        }
        with open(filepath, 'wb') as f:
            pickle.dump(state, f)
        print(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {filepath}")
    
    def load_state(self, filepath: str = "ai_state.pkl"):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                state = pickle.load(f)
                self.parameters = state['parameters']
                self.performance = state['performance']
                self.optimizer.generation = state['generation']
                self.optimizer.fitness_history = state['fitness_history']
            print(f"üìÇ –°–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ {filepath}")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–µ–≥–æ—Å—è –ò–ò
    ai = SelfImprovingAI("–ú–æ–π–°–∞–º–æ—Ä–∞–∑–≤–∏–≤–∞—é—â–∏–π—Å—è–ò–ò")
    
    # –ü—Ä–∏–º–µ—Ä—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
    queries = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å?",
        "–û–±—ä—è—Å–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏—é —Å–∞–º–æ—É–ª—É—á—à–µ–Ω–∏—è",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã?",
        "–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å?"
    ]
    
    print("\n" + "="*60)
    print("–ù–ê–ß–ê–õ–û –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø –° –°–ê–ú–û–†–ê–ó–í–ò–í–ê–Æ–©–ò–ú–°–Ø –ò–ò")
    print("="*60 + "\n")
    
    for i, query in enumerate(queries, 1):
        print(f"\n[–ó–∞–ø—Ä–æ—Å {i}] {query}")
        print("-" * 60)
        response = ai.process(query)
        print(f"–û—Ç–≤–µ—Ç: {response}")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {ai.performance.accuracy:.3f}")
        print(f"–†–∞–∑–º–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {ai.performance.knowledge_base_size}")
        time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
    print("\n" + "="*60)
    print("–§–ò–ù–ê–õ–¨–ù–´–ô –°–¢–ê–¢–£–° –°–ò–°–¢–ï–ú–´")
    print("="*60)
    status = ai.get_status()
    for key, value in status.items():
        print(f"{key}: {value}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    ai.save_state()

